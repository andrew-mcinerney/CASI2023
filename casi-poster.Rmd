---
main_topsize: 0.1 #percent coverage of the poster
main_bottomsize: 0.09
main_subsize: 0.02
#ESSENTIALS
# title: '**Feedforward Neural Networks as Statistical Models**'
poster_height: "46.8in"
poster_width: "33.1in"
main_textsize: "78pt"
author_textsize: "72pt"
affiliation_textsize: "36pt"
twitter_textsize: "50pt"
email_textsize: "50pt"
sup_textsize: "32pt"
body_textsize: "36pt"
code_textsize: "28pt"
outcode_textsize: "24pt"
reference_textsize: "32pt"
# main_img_left_bottom: "0.0in"
# main_img_left_left: "0.0in"
main_img_left_width: "70%"
primary_colour: "#203864"
secondary_colour: "#203864"
accent_colour: "#0099ff"
author:
  - name: '**Andrew McInerney**'
    affil: 1
    main: true
    twitter: amcinerney_
    github: andrew-mcinerney
    email: andrew.mcinerney@ul.ie
  - name: Kevin Burke
    affil: 1
    main: true
    website: kevinburke.ie
affiliation:
  - num: 1
    address: Department of Mathematics & Statistics, University of Limerick
main_findings:
  - "**interpretnn**: **Interpreting** feedforward **neural networks** as **statistical models**"
logoleft_name: figures/banner.png
logoright_name: figures/logo.png
logocenter_name: figures/qr-code-interpretnn.png
output: 
  posterdown::posterdown_betterport:
    self_contained: false
    pandoc_args: --mathjax
    number_sections: false
bibliography: references.bib
link-citations: true
nocite: |
  @interpretnn, @selectnn, @statistically , @interpreting
csl: http://www.zotero.org/styles/apa-5th-edition
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  tidy = FALSE,
  message = FALSE,
  fig.align = "center",
  out.width = "100%"
)
options(knitr.table.format = "html")
```

```{r intnn, cache = TRUE}
library(interpretnn)
library(nnet)

X <- Boston[, -ncol(Boston)]

set.seed(100)
nn <- nnet(medv ~ ., data = Boston,
  size = 2, trace = FALSE,
  linout = TRUE, maxit = 1000
)

intnn <- interpretnn(nn, X = X)
```

&nbsp;

# Introduction

*  Many neural network R packages available:
 **nnet** ([Ripley and Venables, 2022](https://CRAN.R-project.org/package=nnet)), **neuralnet** ([Fritsch, Guenther, and Wright, 2019](https://CRAN.R-project.org/package=neuralnet)), **keras** ([Allaire and Chollet, 2023](https://CRAN.R-project.org/package=keras)), and **torch** ([Falbel and Luraschi, 2023](https://CRAN.R-project.org/package=torch)).
*  Goal of our **interpretnn** package: Allow for more useful and insightful statistical-based methods and outputs.
*  We embed neural networks within likelihood estimation, providing model selection and significance testing.
*  This bridges the gap between the explainability and flexibility of neural networks.

&nbsp;

# Installation
*  You can install the development version of **interpretnn** from [GitHub](https://github.com/) with:

```{r, echo = TRUE, eval = FALSE}
# install.packages("devtools")
devtools::install_github(
  "andrew-mcinerney/interpretnn"
  )
```

&nbsp;

# Implementation

*  Example: Boston Housing dataset.
*  First, we fit the data using the **nnet** package.

```{r, eval = FALSE, echo = TRUE}
library(interpretnn)
library(nnet)
# set.seed(100)
nn <- nnet(medv ~ ., data = Boston,
           size = 2, trace = FALSE,
           linout = TRUE, maxit = 1000)
```

&nbsp;

*  Then, convert this to an `"interpretnn"` object using
the `interpretnn()` function.

```{r, eval = FALSE, echo = TRUE}
intnn <- interpretnn(nn, data = Boston)
```

&nbsp;
&nbsp;

# Model Summary

*  Now, with the `"interpretnn"` object, `summary()` produces a statistically-based model summary.

```{r, echo = TRUE, eval = FALSE}
summary(intnn)
```

```{r, comment = ''}
library(interpretnn)
# cat(c("[...]", capture.output(summary(intnn))[9:24],
#       gsub('(.{1,52})(\\s|$)', '\\1\n',  capture.output(summary(intnn))[25]),
#       "[...]")
#     , sep = "\n")

s <- summary(intnn, wald_single_par = TRUE)$coefdf
s[, 5] <- round(s[, 5], 4)

cat(c("[...]", capture.output(summary(intnn))[4:9],
      capture.output(print(s[, c(1, 7, 4, 5, 6)], row.names = FALSE)),
      capture.output(summary(intnn))[24],
      gsub('(.{1,52})(\\s|$)', '\\1\n', 
           capture.output(summary(intnn))[25]))
    , sep = "\n")

```

&nbsp;

*  `plotnn()` visualises the results of single- and multi-parameter Wald tests overlaid on the network architecture.
*  By default, `alpha = 0.05`, where the weights are coloured black if they are significant, and are grey otherwise (i.e., insignificant).
*  The intercept terms can be displayed by setting `intercept = TRUE` (default: `FALSE`).


```{r, echo = TRUE, eval = FALSE}
plotnn(intnn)
```

```{r}
plotnn(intnn, fontsize = 18, information = FALSE)
```

&nbsp;

*  `plotci()` visualises the single- and joint-parameter Wald (1 - $\alpha$)100\% confidence intervals and ellipses, respectively, for the input-to-hidden-layer weights for each covariate.
*  The `which` argument chooses a particular covariate as the subject of this plot (the default value, `NULL`, produces a plot for each covariate).

&nbsp;

```{r, echo = TRUE, eval = FALSE}
plotci(intnn, which = 12)
```

```{r, echo = FALSE}
plotci(intnn, which = 12, cex.main = 1.6, cex.lab = 1.5, cex.axis = 1.4)
```


# Covariate-Effect Plots
*  `plot()` is used to display the covariate effects.
*  To visualise the associated uncertainty, the `conf_int` argument can be set to `TRUE`.
*  As before, `which` chooses a particular covariate as the subject of this plot (default: `NULL` produces a plot for each covariate).



```{r, echo = TRUE, eval = FALSE}
plot(intnn, which = 12,
     conf_int = TRUE)
```


```{r plot_intnn, cache = TRUE}
plot(intnn, which = 12, conf_int = TRUE,
     cex.caption = 1.6, cex.lab = 1.5, cex.axis = 1.4)
```

&nbsp;

# Acknowledgments
This work has emanated from research conducted with the financial support of Science Foundation Ireland (SFI) under Grant Number SFI 18/CRT/6049.


# References
